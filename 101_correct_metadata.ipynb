{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3c803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\i'\n",
      "/var/folders/b0/68bb2dkj42g1jr38kdd8m6pc0000gp/T/ipykernel_18880/1440002104.py:11: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  image_data['Image Path'] = image_data['Image Path'].str.replace('\\images\\Expo_2000_Ap_8\\PMR_ExStream22_Main_EPT', '')\n"
     ]
    }
   ],
   "source": [
    "# Using Python 3.12.1 (local env: metabarcoding3.0)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from boldigger3.id_engine import parse_fasta\n",
    "\n",
    "fasta_dict, fasta_name, project_directory = parse_fasta('raw/ExStreamEPT_apscale_OTUs_filtered_done.fasta')\n",
    "\n",
    "image_data = pd.read_csv('outputs/image_data_merged_fixed.csv', sep=';',on_bad_lines='warn')\n",
    "image_data['Image Path'] = image_data['Image Path'].str.replace('\\images\\Expo_2000_Ap_8\\PMR_ExStream22_Main_EPT', '')\n",
    "changes_df = pd.read_excel('raw/EPT-14-change-map.xlsx')\n",
    "changes_todo = changes_df[changes_df['Columns to change'] != 'Delete']\n",
    "\n",
    "for index, row in changes_todo.iterrows():\n",
    "    if type(row['New values']) != float:\n",
    "        image_data.loc[image_data['Specimen ID'] == row['Specimen ID'], row['Columns to change'].split(', ')] = row['New values'].split(', ')\n",
    "    else:\n",
    "        image_data.loc[image_data['Specimen ID'] == row['Specimen ID'], row['Columns to change']] = row['New values']\n",
    "\n",
    "image_data['Specimen Weight'] = image_data['Tube Weight with dried Specimen']-image_data['Empty Tube Weight']\n",
    "image_data['Specimen Weight'] = image_data['Specimen Weight'].round(4)\n",
    "\n",
    "# Remove columns that are not needed or given seperatly, since all values are the same (e.g. Species Name (Used as Project Name), Exposure Time (2000 µs), FPS (50), Light Intensity (100%))\n",
    "image_data = image_data.drop(columns=['Species Name', 'Other Notes', 'Aperture', 'Exposure Time (µs)', 'Framerate (FPS)', 'Light Intensity (%)', 'Empty Tube Weight', 'Tube Weight with dried Specimen', 'Plate', 'Well', 'Channel'])\n",
    "bad_img_df = pd.read_excel('raw/EPT_filtered_images.xlsx')\n",
    "image_data.insert(loc=3, column='Passed image QC', value=~image_data['Image File Name'].isin(bad_img_df['bad_img']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2710cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of specimen with <1000 reads in first samples: 132\n",
      "Number of specimen with <1000 reads in repeated samples: 27\n",
      "Number of specimen where Morpho_Order =/= DNA_Order: 20\n",
      "Number of specimen where Morpho_Order =/= DNA_repeat_Order: 7\n"
     ]
    }
   ],
   "source": [
    "# Delete DNA info if reads below 1000 + COUNT\n",
    "# Rename image_data to df for handling reasons:\n",
    "df = image_data\n",
    "\n",
    "# Identify columns that end with '_DNA'\n",
    "data_columns = [col for col in df.columns if '_DNA' not in col]\n",
    "base_df = df[data_columns]\n",
    "dna_columns = [col for col in df.columns if col.endswith('_DNA')]\n",
    "repeat_columns = [col for col in df.columns if col.endswith('_DNA_repeat')]\n",
    "\n",
    "# Set values to NaN where 'read count_DNA' or 'read count_DNA_repeat' is below 1000\n",
    "\n",
    "print(f\"Number of specimen with <1000 reads in first samples: {df.loc[df['read count_DNA'] < 1000, 'Specimen ID'].nunique()}\")\n",
    "not_in_final_df = {}\n",
    "not_in_final_df['delete_in_first'] = df.loc[df['read count_DNA'] < 1000, 'Specimen ID'].unique()\n",
    "print(f\"Number of specimen with <1000 reads in repeated samples: {df.loc[df['read count_DNA_repeat'] < 1000, 'Specimen ID'].nunique()}\")\n",
    "not_in_final_df['delete_in_repeat'] = df.loc[df['read count_DNA_repeat'] < 1000, 'Specimen ID'].unique()\n",
    "\n",
    "df.loc[df['read count_DNA'] < 1000, dna_columns] = np.nan\n",
    "df.loc[df['read count_DNA_repeat'] < 1000, repeat_columns] = np.nan\n",
    "\n",
    "\n",
    "# Delete DNA info if assigned to wrong order for DNA and DNA_repeat\n",
    "non_match_mask = df['Order_DNA'].notna() & (df['Order_DNA'] != df['Order_Morpho'])\n",
    "repeat_non_match_mask = df['Order_DNA_repeat'].notna() & (df['Order_DNA_repeat'] != df['Order_Morpho'])\n",
    "\n",
    "print(f\"Number of specimen where Morpho_Order =/= DNA_Order: {df.loc[non_match_mask, 'Specimen ID'].nunique()}\")\n",
    "not_in_final_df['Morpho_Order =/= DNA_Order'] = df.loc[non_match_mask, 'Specimen ID'].unique()\n",
    "print(f\"Number of specimen where Morpho_Order =/= DNA_repeat_Order: {df.loc[repeat_non_match_mask, 'Specimen ID'].nunique()}\")\n",
    "not_in_final_df['Morpho_Order =/= DNA_repeat_Order'] = df.loc[repeat_non_match_mask, 'Specimen ID'].unique()\n",
    "\n",
    "df.loc[non_match_mask, dna_columns] = np.nan\n",
    "df.loc[repeat_non_match_mask, repeat_columns] = np.nan\n",
    "\n",
    "def determine_final_label(row):\n",
    "    if pd.isna(row['read count_DNA']) and pd.isna(row['read count_DNA_repeat']):\n",
    "        return pd.Series([np.nan] * len(dna_columns), index=dna_columns)  # Both values are NaN\n",
    "    elif pd.isna(row['read count_DNA']):\n",
    "        # Only 'read count_DNA' is NaN, return the '_repeat' values and rename columns\n",
    "        repeat_values = row[repeat_columns].copy()\n",
    "        repeat_values.index = [col.replace('_repeat', '') for col in repeat_values.index]\n",
    "        return repeat_values\n",
    "    elif pd.isna(row['read count_DNA_repeat']):\n",
    "        return row[dna_columns]  # Only 'read count_DNA_repeat' is NaN\n",
    "    else:\n",
    "        # Neither value is NaN, return the row with higher 'read count' and rename columns if needed\n",
    "        if row['read count_DNA'] > row['read count_DNA_repeat']:\n",
    "            return row[dna_columns]\n",
    "        else:\n",
    "            repeat_values = row[repeat_columns].copy()\n",
    "            repeat_values.index = [col.replace('_repeat', '') for col in repeat_values.index]\n",
    "            return repeat_values\n",
    "\n",
    "# Decide if the first run or if the repeated run is chosen based on read count\n",
    "DNA_df = df.apply(determine_final_label, axis = 1)\n",
    "DNA_df = DNA_df.reindex(columns=['OTU_DNA', 'Order_DNA', 'Family_DNA', 'Genus_DNA', 'Species_DNA', 'Label_DNA', 'read count_DNA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8006efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = base_df.join(DNA_df)\n",
    "metadata_df.insert(loc=11, column='Date (DD/MM/YYYY HH:MM:SS)', value=pd.to_datetime(metadata_df['Date (DD/MM/YYYY HH:MM)'], format='%d/%m/%Y %H:%M:%S'))\n",
    "metadata_df = metadata_df.drop(columns=['Date (DD/MM/YYYY HH:MM)'])\n",
    "metadata_df = metadata_df.sort_values(by='Date (DD/MM/YYYY HH:MM:SS)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2275e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.insert(loc=20, column='Seq', value=image_data['OTU_DNA'].apply(lambda x: fasta_dict[x.replace('>', '')].seq if isinstance(x, str) else np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.to_csv('outputs/EPT-14_metadata.csv', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metabarcoding3.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
